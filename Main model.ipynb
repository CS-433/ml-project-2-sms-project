{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"yellow-wilderness"},"outputs":[],"source":["import numpy as np\n","import gc\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset,TensorDataset\n","from torch.optim import lr_scheduler\n","import pandas as pd\n","import pyarrow\n","from torchvision import models, transforms\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report"],"id":"yellow-wilderness"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23055,"status":"ok","timestamp":1702921829183,"user":{"displayName":"baptiste maquignaz","userId":"09858058211747966059"},"user_tz":-60},"id":"nGGne-3u1TSE","outputId":"4524f012-4847-471a-8259-4b082a66ce9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"nGGne-3u1TSE"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3eb-ArGPoBUb"},"outputs":[],"source":["exercise_mapping = {\n","    'Abduction': 0,\n","    'Bird': 1,\n","    'Bridge': 2,\n","    'Knee': 3,\n","    'Shoulder': 4,\n","    'Squat': 5,\n","    'Stretch': 6\n","}\n","set_mapping = {\n","    'Correct' : 0,\n","    'A': 1,\n","    'B': 2,\n","    'C': 3,\n","    'D': 4,\n","    'E': 5,\n","    'F': 6\n","}"],"id":"3eb-ArGPoBUb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"uYd4BrSRyxxu"},"outputs":[],"source":["#Importing pre dataset\n","train_df = pd.read_parquet('/content/drive/MyDrive/ML_project/RNN/train_set_not_std_less_noise.parquet', engine='pyarrow')\n","test_df = pd.read_parquet('/content/drive/MyDrive/ML_project/test_set_not_std.parquet', engine='pyarrow')"],"id":"uYd4BrSRyxxu"},{"cell_type":"code","execution_count":null,"metadata":{"id":"iGK8DAIxqmQE"},"outputs":[],"source":["video_indices = test_df.groupby('video_id').size().values\n","video_indices = np.insert(video_indices, 0, 0)\n","video_indices = np.cumsum(video_indices)"],"id":"iGK8DAIxqmQE"},{"cell_type":"code","source":["get_mlp3x256 = lambda: torch.nn.Sequential(\n","\n","    torch.nn.Flatten(),\n","    torch.nn.Linear(100, 256),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(256, 256),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(256, 256),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(256, 256),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(256, 7),\n",")"],"metadata":{"id":"LQSJUeklXg32"},"id":"LQSJUeklXg32","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bdHQHrzx4wdq"},"outputs":[],"source":["get_physio_mlp = lambda: torch.nn.Sequential(\n","\n","    nn.Flatten(),\n","    nn.Linear(107, 512),\n","    nn.BatchNorm1d(512),\n","    nn.ReLU(),\n","    nn.Dropout(0.3),\n","    nn.Linear(512, 512),\n","    nn.BatchNorm1d(512),\n","    nn.ReLU(),\n","    nn.Dropout(0.3),\n","    nn.Linear(512, 512),\n","    nn.BatchNorm1d(512),\n","    nn.ReLU(),\n","    nn.Dropout(0.3),\n","    nn.Linear(512, 512),\n","    nn.BatchNorm1d(512),\n","    nn.ReLU(),\n","    nn.Linear(512, 7)\n",")"],"id":"bdHQHrzx4wdq"},{"cell_type":"markdown","metadata":{"id":"g7I_TUn5wXRx"},"source":["# Training the model to predict exercises\n","We first split the train and test set\n"],"id":"g7I_TUn5wXRx"},{"cell_type":"code","execution_count":null,"metadata":{"id":"BcRVUlhaseFY"},"outputs":[],"source":["X_train, X_test, y_train, y_test = helpers.import_data_exercise(train_df, test_df, exercise_mapping, True)"],"id":"BcRVUlhaseFY"},{"cell_type":"markdown","source":["We then define everything we need to train our model"],"metadata":{"id":"pa17ibuZYBAb"},"id":"pa17ibuZYBAb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"suffering-nudist"},"outputs":[],"source":["#Defines hyperparameters\n","learning_rate = 2e-3\n","batch_size = 128\n","\n","# Creates an instance of the dataset\n","dataset = TensorDataset(X_train, y_train)\n","\n","# Creates a DataLoader\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# Defines the model\n","model = get_mlp3x256_ex()\n","model.train()\n","\n","# Defines the path to save the model's state dictionnary\n","model_path = '/content/drive/MyDrive/ML_project/MLPEX.path'\n","\n","# Defines loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# Creates an optimizer\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Creates a scheduler\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)"],"id":"suffering-nudist"},{"cell_type":"markdown","source":["We procede to train the model. It converges to sufficiently trained state to perform 100% accuracy on test set in a single iteration. Note that the already trained model state dictionnary can be loaded from the path 'MLPEX_trained.path' by uncommenting the cell below."],"metadata":{"id":"-Ve3LpE1Zndd"},"id":"-Ve3LpE1Zndd"},{"cell_type":"code","source":["model.load_state_dict(torch.load('MLPEX_trained.path'))"],"metadata":{"id":"2Ft7Cfhubd-J"},"id":"2Ft7Cfhubd-J","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":470},"executionInfo":{"elapsed":8931,"status":"error","timestamp":1702921904743,"user":{"displayName":"baptiste maquignaz","userId":"09858058211747966059"},"user_tz":-60},"id":"armed-trail","outputId":"8892f81c-e661-4727-fb43-8bc0de55fdd2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing: 2.38%"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-7344d74187a5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvideo_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-727dada78db4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(num_epochs, model, optimizer, criterion, dataloader, scheduler, save_path, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Backward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Trains the model\n","helpers.train_model(1, model, optimizer, criterion, dataloader, scheduler, model_path)\n","\n","# Prints a report on the accuracy and F1 score\n","helpers.test_accuracy(model, X_test,y_test,video_indices)"],"id":"armed-trail"},{"cell_type":"markdown","metadata":{"id":"C9M6v2fhwm0S"},"source":["#Training of MLP 3x256 to predict sets"],"id":"C9M6v2fhwm0S"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ShqlDMUXutXg"},"outputs":[],"source":["X_train, X_test, y_train, y_test = import_data_set(train_df, test_df, set_mapping, True)"],"id":"ShqlDMUXutXg"},{"cell_type":"code","execution_count":null,"metadata":{"id":"NtUqeJc4583a"},"outputs":[],"source":["#Defines hyperparameters\n","learning_rate = 0.001\n","batch_size = 128\n","\n","# Creates an instance of the dataset\n","dataset = TensorDataset(X_train, y_train)\n","\n","# Creates a DataLoader\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# Defines the model\n","model = get_mlp3x256_set()\n","model.train()\n","\n","# Defines the path to save the model's state dictionnary\n","model_path = '/content/drive/MyDrive/ML_project/PhysioMLP.path'\n","\n","# Defines loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# Creates an optimizer\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Creates a scheduler\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.8)"],"id":"NtUqeJc4583a"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"EZiRAlm45-jE","outputId":"d64ab15b-1dd8-4099-a4af-5214c0621528"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing: 100.00%Epoch [1/1], Loss: 1.2220\n","Accuracy on each frame: 0.4192\n","Accuracy for videos: 0.5190\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.83      0.60       140\n","           1       0.58      0.34      0.43        76\n","           2       0.71      0.35      0.47        72\n","           3       0.50      0.39      0.44        64\n","           4       0.78      0.45      0.57        40\n","           5       0.60      0.38      0.46        16\n","           6       0.22      0.17      0.19        12\n","\n","    accuracy                           0.52       420\n","   macro avg       0.55      0.41      0.45       420\n","weighted avg       0.56      0.52      0.50       420\n","\n","Processing: 100.00%Epoch [1/1], Loss: 1.2193\n","Accuracy on each frame: 0.4184\n","Accuracy for videos: 0.5238\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.84      0.60       140\n","           1       0.58      0.34      0.43        76\n","           2       0.68      0.35      0.46        72\n","           3       0.53      0.41      0.46        64\n","           4       0.77      0.42      0.55        40\n","           5       0.60      0.38      0.46        16\n","           6       0.30      0.25      0.27        12\n","\n","    accuracy                           0.52       420\n","   macro avg       0.56      0.43      0.46       420\n","weighted avg       0.56      0.52      0.51       420\n","\n","Processing: 100.00%Epoch [1/1], Loss: 1.2182\n","Accuracy on each frame: 0.4208\n","Accuracy for videos: 0.5167\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.82      0.60       140\n","           1       0.60      0.37      0.46        76\n","           2       0.65      0.33      0.44        72\n","           3       0.51      0.38      0.43        64\n","           4       0.77      0.42      0.55        40\n","           5       0.60      0.38      0.46        16\n","           6       0.27      0.25      0.26        12\n","\n","    accuracy                           0.52       420\n","   macro avg       0.55      0.42      0.46       420\n","weighted avg       0.56      0.52      0.50       420\n","\n","Processing: 100.00%Epoch [1/1], Loss: 1.2167\n","Accuracy on each frame: 0.4226\n","Accuracy for videos: 0.5167\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.83      0.60       140\n","           1       0.57      0.34      0.43        76\n","           2       0.64      0.35      0.45        72\n","           3       0.51      0.38      0.43        64\n","           4       0.81      0.42      0.56        40\n","           5       0.60      0.38      0.46        16\n","           6       0.27      0.25      0.26        12\n","\n","    accuracy                           0.52       420\n","   macro avg       0.55      0.42      0.46       420\n","weighted avg       0.55      0.52      0.50       420\n","\n","Processing: 100.00%Epoch [1/1], Loss: 1.2164\n","Accuracy on each frame: 0.4212\n","Accuracy for videos: 0.5214\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.84      0.60       140\n","           1       0.59      0.36      0.44        76\n","           2       0.68      0.38      0.48        72\n","           3       0.51      0.36      0.42        64\n","           4       0.77      0.42      0.55        40\n","           5       0.60      0.38      0.46        16\n","           6       0.20      0.17      0.18        12\n","\n","    accuracy                           0.52       420\n","   macro avg       0.55      0.41      0.45       420\n","weighted avg       0.56      0.52      0.50       420\n","\n","Processing: 100.00%Epoch [1/1], Loss: 1.2145\n","Accuracy on each frame: 0.4215\n","Accuracy for videos: 0.5262\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.84      0.61       140\n","           1       0.59      0.36      0.44        76\n","           2       0.65      0.36      0.46        72\n","           3       0.53      0.39      0.45        64\n","           4       0.77      0.42      0.55        40\n","           5       0.60      0.38      0.46        16\n","           6       0.27      0.25      0.26        12\n","\n","    accuracy                           0.53       420\n","   macro avg       0.56      0.43      0.46       420\n","weighted avg       0.56      0.53      0.51       420\n","\n","Processing: 100.00%Epoch [1/1], Loss: 1.2148\n","Accuracy on each frame: 0.4215\n","Accuracy for videos: 0.5262\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.83      0.61       140\n","           1       0.59      0.36      0.44        76\n","           2       0.66      0.38      0.48        72\n","           3       0.52      0.39      0.45        64\n","           4       0.77      0.42      0.55        40\n","           5       0.60      0.38      0.46        16\n","           6       0.27      0.25      0.26        12\n","\n","    accuracy                           0.53       420\n","   macro avg       0.56      0.43      0.46       420\n","weighted avg       0.56      0.53      0.51       420\n","\n","Processing: 100.00%Epoch [1/1], Loss: 1.2145\n","Accuracy on each frame: 0.4211\n","Accuracy for videos: 0.5238\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.84      0.61       140\n","           1       0.59      0.36      0.44        76\n","           2       0.65      0.36      0.46        72\n","           3       0.52      0.38      0.44        64\n","           4       0.77      0.42      0.55        40\n","           5       0.60      0.38      0.46        16\n","           6       0.27      0.25      0.26        12\n","\n","    accuracy                           0.52       420\n","   macro avg       0.55      0.43      0.46       420\n","weighted avg       0.56      0.52      0.51       420\n","\n","Processing: 100.00%Epoch [1/1], Loss: 1.2143\n","Accuracy on each frame: 0.4211\n","Accuracy for videos: 0.5262\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.84      0.61       140\n","           1       0.60      0.36      0.45        76\n","           2       0.65      0.36      0.46        72\n","           3       0.53      0.39      0.45        64\n","           4       0.77      0.42      0.55        40\n","           5       0.60      0.38      0.46        16\n","           6       0.27      0.25      0.26        12\n","\n","    accuracy                           0.53       420\n","   macro avg       0.56      0.43      0.46       420\n","weighted avg       0.56      0.53      0.51       420\n","\n","Processing: 100.00%Epoch [1/1], Loss: 1.2140\n","Accuracy on each frame: 0.4209\n","Accuracy for videos: 0.5262\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.48      0.84      0.61       140\n","           1       0.58      0.34      0.43        76\n","           2       0.66      0.38      0.48        72\n","           3       0.53      0.39      0.45        64\n","           4       0.77      0.42      0.55        40\n","           5       0.60      0.38      0.46        16\n","           6       0.27      0.25      0.26        12\n","\n","    accuracy                           0.53       420\n","   macro avg       0.56      0.43      0.46       420\n","weighted avg       0.56      0.53      0.51       420\n","\n"]}],"source":["for i in range(30):\n","  # Trains the model\n","  train_model(1, model, optimizer, criterion, dataloader, scheduler, model_path, batch_size)\n","\n","  # Prints a report on the accuracy and F1 score\n","  test_accuracy(model, X_test,y_test,video_indices)"],"id":"EZiRAlm45-jE"}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}